// Encoder: WebCodecs ã§å†ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€mp4-muxer ã§ FileSystem ã¸ä¿å­˜
// Muxer ã¨ FileSystemWritableFileStreamTarget ã¯ index.html ã§ window.Mp4MuxerClasses ã«è¨­å®šã•ã‚Œã‚‹

// onProgress ã®å‘¼ã³å‡ºã—å½¢å¼: onProgress({ stage, percent, fps, elapsedMs })
// stage: 'demuxing' (ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿&ãƒ‡ãƒžãƒƒã‚¯ã‚¹), 'encoding' (ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰)

export async function encodeToFile(file, config, onProgress, demuxAndDecode) {
    console.log('encodeToFile started');

    console.log('Opening save file picker...');
    const handle = await window.showSaveFilePicker({
        suggestedName: 'output.mp4',
        types: [{ description: 'Video File', accept: { 'video/mp4': ['.mp4'] } }]
    });
    console.log('File picker completed');
    const fileStream = await handle.createWritable();

    let frameCount = 0;
    const start = performance.now();
    let videoChunkCount = 0;
    let videoChunkAddedCount = 0;
    let audioChunkCount = 0;
    let audioChunkAddedCount = 0;
    let muxer = null;
    let audioEncoder = null;
    let audioEncoderClosed = false;
    let totalVideoDurationUs = 0;
    let encodedVideoUs = 0;
    let videoBaseTsUs = null;
    let audioBaseTsUs = null;
    let muxerInitialized = false;
    let detectedAudioFormat = null;
    
    // Track expected frame count and completion
    let expectedFrameCount = 0;
    let encodingComplete = null;
    let encodingCompleted = false;
    const encodingCompletePromise = new Promise((resolve) => {
        encodingComplete = resolve;
    });

    const videoEncoder = new VideoEncoder({
        output: (chunk, meta) => {
            videoChunkCount++;
            if (videoChunkCount === 1) {
                console.log('ðŸŽ¬ FIRST VIDEO CHUNK:', {
                    size: chunk.byteLength,
                    timestamp: chunk.timestamp,
                    duration: chunk.duration,
                    type: chunk.type,
                    isKeyFrame: chunk.type === 'key'
                });
            }
            if (muxerInitialized && muxer) {
                // addVideoChunkRaw() expects timestamps and durations in microseconds
                const tsUs = Number(chunk.timestamp) || 0;
                const durUs = Number(chunk.duration) || 0;

                if (videoBaseTsUs === null) {
                    videoBaseTsUs = tsUs;
                    console.log('videoBaseTsUs initialized:', videoBaseTsUs);
                }
                const normalizedTsUs = Math.max(0, tsUs - videoBaseTsUs);

                try {
                    if (videoChunkCount <= 3 || videoChunkCount % 500 === 0) {
                        console.log(`[CHUNK ${videoChunkCount}] ts: ${normalizedTsUs.toFixed(2)}us, dur: ${durUs.toFixed(2)}us, type: ${chunk.type}`);
                    }

                    // addVideoChunkRaw() expects timestamp and duration in microseconds
                    const data = new Uint8Array(chunk.byteLength);
                    chunk.copyTo(data);
                    muxer.addVideoChunkRaw(data, chunk.type, normalizedTsUs, durUs, meta);

                    videoChunkAddedCount++;
                } catch (e) {
                    // ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’è©³ç´°ã«è¨˜éŒ²
                    console.error(`âœ— Failed to add chunk #${videoChunkCount}:`, {
                        message: e.message,
                        timestamp: tsUs,
                        normalizedTsUs: normalizedTsUs,
                        duration: durUs,
                        chunk_type: chunk.type,
                        full_error: e.toString()
                    });
                    // timestamp ã‚¨ãƒ©ãƒ¼ä»¥å¤–ã¯å†ã‚¹ãƒ­ãƒ¼
                    if (!e.message?.includes('timestamp')) {
                        throw e;
                    }
                }
            }
            // ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é€²æ—ã‚’ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰æ¸ˆã¿ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§æŽ¨å®š
            if (totalVideoDurationUs > 0) {
                const tsRaw = Number(chunk.timestamp) || 0;
                const dur = Number(chunk.duration) || 0;
                const base = videoBaseTsUs ?? tsRaw;
                const tsNorm = Math.max(0, tsRaw - base);
                encodedVideoUs = Math.max(encodedVideoUs, tsNorm + dur);
                const encPercent = Math.min(100, 100 * (encodedVideoUs / totalVideoDurationUs));
                if (videoChunkCount % 100 === 0) {
                    console.log('Encoding progress:', encPercent.toFixed(1) + '%, encoded:', encodedVideoUs, 'total:', totalVideoDurationUs);
                }
                onProgress({ stage: 'encoding', percent: encPercent, fps: undefined, elapsedMs: performance.now() - start });
            } else if (videoChunkCount === 1) {
                console.log('Warning: totalVideoDurationUs is', totalVideoDurationUs);
            }
            
            // Check if all expected chunks have been encoded
            // Note: expectedFrameCount > 0 guard prevents premature resolution if chunks arrive
            // before expectedFrameCount is set (after demuxAndDecode completes)
            if (expectedFrameCount > 0 && videoChunkCount >= expectedFrameCount && !encodingCompleted) {
                console.log('All expected video chunks encoded:', videoChunkCount, '/', expectedFrameCount);
                encodingCompleted = true;
                encodingComplete();
            }
        },
        error: (e) => console.error('VideoEncoder error', e)
    });

    // VideoEncoderã¯åˆæœŸè¨­å®šï¼ˆå®Ÿéš›ã®è¨­å®šã¯å¾Œã§onReadyã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å†…ã§è¡Œã†ï¼‰
    videoEncoder.configure({
        codec: config.video.codec ?? 'avc1.640028',
        width: config.video.width,
        height: config.video.height,
        bitrate: config.video.bitrate,
        framerate: config.video.framerate,
        latencyMode: 'quality'
    });

    const videoDecoder = new VideoDecoder({
        output: (frame) => {
            frameCount++;
            if (frameCount === 1) {
                console.log('ðŸŽ¥ FIRST DECODED FRAME:', {
                    format: frame.format,
                    width: frame.codedWidth,
                    height: frame.codedHeight,
                    displayWidth: frame.displayWidth,
                    displayHeight: frame.displayHeight,
                    timestamp: frame.timestamp,
                    duration: frame.duration
                });
            }
            if (frameCount <= 3 || frameCount % 500 === 0) {
                console.log(`[DECODE #${frameCount}] ${frame.codedWidth}x${frame.codedHeight} ts=${frame.timestamp}`);
            }
            try {
                // æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯å¼·åˆ¶çš„ã«ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ãƒ ã«ã™ã‚‹
                const encodeOptions = (frameCount === 1) ? { keyFrame: true } : undefined;
                videoEncoder.encode(frame, encodeOptions);
            } catch (encErr) {
                console.error(`âŒ VideoEncoder.encode() FAILED at frame #${frameCount}:`, {
                    frameSize: `${frame.codedWidth}x${frame.codedHeight}`,
                    frameFormat: frame.format,
                    error: encErr.message
                });
                throw encErr;
            }
            frame.close();
            const elapsedMs = performance.now() - start;
            const fps = frameCount / (elapsedMs / 1000);
            // FPSæƒ…å ±ã¨çµŒéŽæ™‚é–“ã®ã¿æ›´æ–°ï¼ˆstage/percentã¯å«ã‚ãªã„ï¼‰
            onProgress({ fps, elapsedMs });
        },
        error: (e) => console.error('VideoDecoder error', e)
    });

    let audioFormatWarned = false;
    const audioDecoder = config.audio ? new AudioDecoder({
        output: (audioData) => {
            if (audioEncoder && !audioEncoderClosed && audioEncoder.state !== 'closed') {
                // Check if detected format is available and matches decoded audio
                // Only warn if there's a mismatch with the detected format
                if (!audioFormatWarned && detectedAudioFormat &&
                    (audioData.sampleRate !== detectedAudioFormat.sampleRate ||
                        audioData.numberOfChannels !== detectedAudioFormat.numberOfChannels)) {
                    console.warn('Audio format mismatch! Decoded audio:', {
                        sampleRate: audioData.sampleRate,
                        channels: audioData.numberOfChannels
                    }, 'Expected (detected):', {
                        sampleRate: detectedAudioFormat.sampleRate,
                        channels: detectedAudioFormat.numberOfChannels
                    });
                    console.warn('Audio format mismatch detected. This may indicate an issue with the format detection logic or unexpected audio stream properties.');
                    audioFormatWarned = true;
                }

                // Encode all audio data - the AudioEncoder is configured in onReady callback
                // with the detected audio format (detectedFormat.audio.sampleRate and numberOfChannels)
                audioEncoder.encode(audioData);
            }
            audioData.close();
        },
        error: (e) => console.error('AudioDecoder error', e)
    }) : null;

    // ===== SINGLE-PASS ENCODING: Format detection and encoding in one pass =====
    console.log('Starting single-pass encoding with format detection...');
    onProgress({ stage: 'demuxing', percent: 0, fps: 0, elapsedMs: 0 });

    // onReady callback: åˆæœŸåŒ–å‡¦ç†ï¼ˆMuxer, AudioEncoderï¼‰
    const onReady = async (detectedFormat) => {
        console.log('onReady callback fired with format:', detectedFormat);
        
        totalVideoDurationUs = Number(detectedFormat.video?.durationUs) || 0;
        console.log('Total video duration:', totalVideoDurationUs, 'us');

        // Store detected audio format for use in AudioDecoder output callback
        detectedAudioFormat = detectedFormat.audio;

        // æ¤œå‡ºã•ã‚ŒãŸå®Ÿéš›ã®è§£åƒåº¦ã§ encoder/muxer ã‚’è¨­å®š
        let actualWidth = detectedFormat.video?.width || config.video.width;
        let actualHeight = detectedFormat.video?.height || config.video.height;

        console.log('Resolution check: width=', actualWidth, 'height=', actualHeight, 'pixels=', actualWidth * actualHeight);

        // AVC Level 5.0åˆ¶é™: æœ€å¤§2228224ãƒ”ã‚¯ã‚»ãƒ«
        const maxPixels = 2228224;
        if (actualWidth * actualHeight > maxPixels) {
            console.log('Resolution exceeds AVC Level 5.0 limit, normalizing to 1920x1080');
            actualWidth = 1920;
            actualHeight = 1080;
        }

        // ===== VideoEncoder å†è¨­å®š =====
        console.log('\nðŸŽ¬ VideoEncoder re-configuration');
        console.log(`  Input video format: ${detectedFormat.video.width}x${detectedFormat.video.height}`);
        console.log(`  Encoder will be configured as: ${actualWidth}x${actualHeight}`);
        if (detectedFormat.video.width !== actualWidth || detectedFormat.video.height !== actualHeight) {
            console.warn(`  âš ï¸  RESOLUTION WILL BE CHANGED: ${detectedFormat.video.width}x${detectedFormat.video.height} â†’ ${actualWidth}x${actualHeight}`);
        }

        videoEncoder.configure({
            codec: config.video.codec ?? 'avc1.640028',
            width: actualWidth,
            height: actualHeight,
            bitrate: config.video.bitrate,
            framerate: config.video.framerate,
            latencyMode: 'quality',
            avc: { format: 'avc' }
        });
        console.log('âœ… VideoEncoder configured:', { 
            width: actualWidth, 
            height: actualHeight, 
            bitrate: config.video.bitrate,
            codec: config.video.codec,
            framerate: config.video.framerate
        });

        // ===== Muxer åˆæœŸåŒ– =====
        console.log('Initializing Muxer...');
        const { Muxer, FileSystemWritableFileStreamTarget } = window.Mp4MuxerClasses;
        muxer = new Muxer({
            target: new FileSystemWritableFileStreamTarget(fileStream),
            video: { codec: 'avc', width: actualWidth, height: actualHeight },
            audio: detectedFormat.audio && config.audio ? {
                codec: 'aac',
                sampleRate: detectedFormat.audio.sampleRate,
                numberOfChannels: detectedFormat.audio.numberOfChannels
            } : undefined,
            fastStart: false
        }, {
            firstTimestampBehavior: 'remove'
        });
        console.log('Muxer initialized and ready for chunks');
        // Set flag AFTER muxer is fully initialized
        muxerInitialized = true;

        // ===== AudioEncoder åˆæœŸåŒ– =====
        if (detectedFormat.audio && config.audio) {
            audioEncoder = new AudioEncoder({
                output: (chunk, meta) => {
                    audioChunkCount++;
                    if (audioChunkCount === 1) {
                        console.log('First audio chunk received, size:', chunk.byteLength);
                    }
                    const ts = Number(meta?.timestamp) || 0;
                    if (audioBaseTsUs === null) audioBaseTsUs = ts;
                    const normalizedTs = Math.max(0, ts - audioBaseTsUs);
                    // æœ€åˆã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ£ãƒ³ã‚¯ã¯ timestamp: 0 ã¨ã—ã¦æŒ‡å®š
                    const finalTs = audioChunkCount === 1 ? 0 : normalizedTs;
                    const metaAdj = { ...meta, timestamp: finalTs };
                    try {
                        muxer.addAudioChunk(chunk, metaAdj);
                        audioChunkAddedCount++;
                        if (audioChunkCount % 100 === 0) {
                            console.log(`âœ“ Audio chunks added: ${audioChunkAddedCount}/${audioChunkCount}`);
                        }
                    } catch (e) {
                        console.error(`âœ— Failed to add audio chunk #${audioChunkCount}:`, {
                            message: e.message,
                            timestamp: ts,
                            normalizedTs: normalizedTs,
                            full_error: e.toString()
                        });
                        if (!e.message?.includes('timestamp')) {
                            throw e;
                        }
                    }
                },
                error: (e) => {
                    console.error('AudioEncoder error', e);
                    audioEncoderClosed = true;
                }
            });

            audioEncoder.configure({
                codec: config.audio.codec ?? 'mp4a.40.2',
                sampleRate: detectedFormat.audio.sampleRate,
                numberOfChannels: detectedFormat.audio.numberOfChannels,
                bitrate: config.audio.bitrate
            });
            console.log('AudioEncoder configured with detected format:', detectedFormat.audio);
        }
    };

    // å˜ä¸€ãƒ‘ã‚¹ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆonReadyã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§åˆæœŸåŒ–ï¼‰
    const demuxResult = await demuxAndDecode(file, videoDecoder, audioDecoder, (pct) => {
        const percent = pct;
        onProgress({ stage: 'demuxing', percent, fps: undefined, elapsedMs: performance.now() - start });
    }, onReady);
    
    // Set expected frame count from demuxer result
    expectedFrameCount = demuxResult?.video?.sampleCount || 0;
    console.log('Expected video frames from demuxer:', expectedFrameCount);
    
    // Check if encoding is already complete or resolve immediately if no frames expected
    if (expectedFrameCount === 0 || videoChunkCount >= expectedFrameCount) {
        if (expectedFrameCount === 0) {
            console.log('No video frames expected, resolving encoding promise');
        } else {
            console.log('All chunks already encoded before check:', videoChunkCount, '/', expectedFrameCount);
        }
        encodingCompleted = true;
        encodingComplete();
    }

    console.log('\n' + '='.repeat(70));
    console.log('ðŸ“Š ENCODING SUMMARY:');
    console.log(`  Frames decoded: ${frameCount}`);
    console.log(`  Video chunks encoded: ${videoChunkCount}`);
    console.log(`  Video chunks ADDED to muxer: ${videoChunkAddedCount}`);
    console.log(`  Failed/Missing: ${videoChunkCount - videoChunkAddedCount}`);
    console.log(`  Audio chunks: ${audioChunkCount} (added: ${audioChunkAddedCount})`);
    if (videoChunkAddedCount === 0) {
        console.error('\nâŒ CRITICAL: NO video chunks added to muxer!');
        console.error('   Investigating causes:');
        console.error('   - Muxer initialization failed?');
        console.error('   - Resolution mismatch?');
        console.error('   - All chunks were delta frames (no key frame)?');
    }
    console.log('='.repeat(70) + '\n');

    console.log('Flushing encoders...');
    onProgress({ stage: 'encoding', percent: 100, fps: undefined, elapsedMs: performance.now() - start });
    console.log('Total frames decoded:', frameCount);
    console.log('Total video chunks encoded:', videoChunkCount);
    console.log('Total video chunks added to muxer:', videoChunkAddedCount);
    console.log('Total audio chunks encoded:', audioChunkCount);
    console.log('Total audio chunks added to muxer:', audioChunkAddedCount);

    console.log('Before encoder flush - frames decoded:', frameCount, 'chunks encoded:', videoChunkCount);
    await videoEncoder.flush();
    if (audioEncoder) await audioEncoder.flush();
    console.log('After encoder flush - frames decoded:', frameCount, 'chunks encoded:', videoChunkCount);
    
    // Wait for all encoded chunks to be processed
    console.log('Waiting for all video chunks to be encoded...');
    if (expectedFrameCount > 0 && videoChunkCount < expectedFrameCount) {
        console.log(`Still waiting for chunks: ${videoChunkCount}/${expectedFrameCount}`);
        console.log(`Current state - Frames decoded: ${frameCount}, Chunks encoded: ${videoChunkCount}, Chunks added to muxer: ${videoChunkAddedCount}`);
        
        await encodingCompletePromise;
        console.log('All video chunks have been encoded');
        console.log(`Final state - Frames decoded: ${frameCount}, Chunks encoded: ${videoChunkCount}, Chunks added to muxer: ${videoChunkAddedCount}`);
    } else if (expectedFrameCount > 0) {
        console.log('All expected chunks already encoded');
    } else {
        console.warn('No expected frame count available, proceeding without waiting');
    }

    console.log('Finalizing muxer...');
    muxer.finalize();

    // Wait for muxer to flush all buffered data (including moov atom) to the stream
    // Without this delay, the fileStream.close() can happen before the muxer writes the final metadata,
    // resulting in "moov atom not found" error
    console.log('Waiting for muxer to flush buffered data...');
    await new Promise(resolve => setTimeout(resolve, 100));

    console.log('Closing file stream...');
    await fileStream.close();

    console.log('Encode complete!');
}
